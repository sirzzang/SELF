{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 데이터 수집, 분석의 관점에서 스크랩한 정보를 저장해야 한다.\n",
    " \n",
    " \n",
    " 저장하는 방법에는 *1)**참조를 저장**하는 방법*과, *2)**파일 자체를 저장**하는 방법*이 있다. 첫번째 방법은 파일이 위치한 URL을 저장하는 것이다. 그러나 파일을 한두 번 이상 실제로 보거나 읽어야 한다면, 두 번째 방법을 사용하는 것이 좋다.\n",
    " \n",
    "---\n",
    "\n",
    " \n",
    " # 파일 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 미디어 파일 저장\n",
    "\n",
    "* 기초 : 내려 받을 파일이 하나이고, 이름과 확장자를 어떻게 정할지 알고 있을 때.\n",
    "* 최종 : 기초 ver. 확장하여 특정 속성이 있는 태그에 연결된 내용을 모두 내려받음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기초 ver.\n",
    "* `urllib.request.urlretrieve` : 원격 URL의 파일 다운로드.\n",
    "* 해당 디렉토리에 `logo.jpg`라는 이름으로 저장됨.\n",
    "* `.find` 메서드를 썼기 때문에, 여러 장의 이미지 중 첫 이미지만 다운로드된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('logo.jpg', <http.client.HTTPMessage at 0x1f85030a2e8>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# module import\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 이미지 파일 다운로드 : src 속성 `img`\n",
    "html = urlopen(\"http://www.pythonscraping.com/\")\n",
    "bs = BeautifulSoup(html, 'html.parser') # BeautifulSoup 객체 생성\n",
    "imageLocation = bs.find('a', {\"id\" : \"logo\"}).find('img')['src']     # id가 logo인 a 태그 아래에\n",
    "                                             # 'img'라는 태그를 찾고, 그 이미지에서 src 속성을 가져온다.\n",
    "urlretrieve(imageLocation, 'logo.jpg') # 위의 이미지 경로를 저장. 첫 번째 이미지만 찾아 저장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 종합 ver.\n",
    "* 홈페이지에서 해당 속성이 있는 태그에 연결된 파일을 모두 내려받는다.\n",
    "    - 람다 함수 사용해 `src` 속성 모두 선택.\n",
    "    - URL 손질하여 절대 경로로 바꾸고 내려 받을 준비를 한다.\n",
    "    - 컴퓨터의 `downloaded` 폴더 안에 경로를 유지하면서 내려 받는다.\n",
    "* `os` 모듈 : 파이썬과 운영체제 사이의 인터페이스 역할(파일 경로 조작, 디렉터리 생성, 실행 중인 프로세스와 환경변수에 관한 정보 등)\n",
    "    - 각 파일이 저장될 디렉터리가 있는지 확인.\n",
    "    - 없다면 디렉터리를 생성한다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://pythonscraping.com/misc/jquery.js?v=1.4.4\n",
      "http://pythonscraping.com/misc/jquery.once.js?v=1.2\n",
      "http://pythonscraping.com/misc/drupal.js?q4na2g\n",
      "http://pythonscraping.com/sites/all/themes/skeletontheme/js/jquery.mobilemenu.js?q4na2g\n",
      "http://pythonscraping.com/sites/all/modules/google_analytics/googleanalytics.js?q4na2g\n",
      "http://pythonscraping.com/sites/default/files/lrg_0.jpg\n",
      "http://pythonscraping.com//https://covers.oreillystatic.com/images/0636920078067/lrg.jpg\n",
      "http://pythonscraping.com/img/lrg%20(1).jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('downloadedimg/lrg%20(1).jpg', <http.client.HTTPMessage at 0x1f851084e80>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# module import\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 파일 다운로드할 경로\n",
    "download_dir = \"downloaded\" # 폴더\n",
    "baseUrl = \"http://pythonscraping.com/\" # 다운로드할 홈페이지\n",
    "\n",
    "# URL 손질 후 절대경로 얻는 함수\n",
    "# 애초에 홈페이지가 http://pythonscraping.com이다. 그런데 이미지 src에는 http://www.로 시작하니까 바꿔야.\n",
    "def getAbsoluteUrl(baseUrl, source): # source가 뭐지?\n",
    "    if source.startswith(\"http://www.\") : # 이미지 저장되어 있는 경로가 절대 http://www로 시작한다면\n",
    "        url = \"http://{}\".format(source[11:]) # www 뒤의 경로만 받는다.\n",
    "    elif source.startswith(\"http://\") : # www.없이 그냥 http로 바로 시작하면 그게 절대경로.\n",
    "        url = source\n",
    "    elif source.startswith(\"www.\"):\n",
    "        url = source[4:] # www 뒤의 부분만 url로 받는다.\n",
    "        url = \"http://{}\".format(source)\n",
    "    else:\n",
    "        url = \"{}/{}\".format(baseUrl, source)\n",
    "    if baseUrl not in url: # url 오류\n",
    "        return None\n",
    "    return url\n",
    "\n",
    "# 다운로드할 경로 얻는 함수\n",
    "def getDownloadPath(baseUrl, absoluteUrl, downloadDirectory): # 다운로드 경로\n",
    "    path = absoluteUrl.replace('www.', '') # www. 없애기\n",
    "    path = path.replace(baseUrl, '') # url도 없애기\n",
    "    path = download_dir + path\n",
    "    directory = os.path.dirname(path) # 디렉토리 형성 : Q) \"./\" 이런거 안 해도 되나?????\n",
    "    \n",
    "    if not os.path.exists(directory): # 디렉토리 없으면 만들고\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    return path\n",
    "\n",
    "html = urlopen(\"http://www.pythonscraping.com\") # html 열 때는 baseUrl 여는 게 아니다!\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "downloadList = bs.findAll(src = True) # 'src' 속성이 있는 애들만 다운로드!\n",
    "\n",
    "for download in downloadList:\n",
    "    fileUrl = getAbsoluteUrl(baseUrl, download['src'])\n",
    "    if fileUrl is not None:\n",
    "        print(fileUrl)\n",
    "\n",
    "urlretrieve(fileUrl, getDownloadPath(baseUrl, fileUrl, download_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 공부해볼 것.\n",
    "* http://pythonscraping.com/sites/default/files/lrg_0.jpg :다운로드 경로 downloadedsites/default/files\n",
    "* http://pythonscraping.com/img/lrg%20(1).jpg : 다운로드 경로 downloadedimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://pythonscraping.com/misc/jquery.js?v=1.4.4\n",
      "[Errno 22] Invalid argument: 'downloadedmisc/jquery.js?v=1.4.4'\n",
      "http://pythonscraping.com/misc/jquery.once.js?v=1.2\n",
      "[Errno 22] Invalid argument: 'downloadedmisc/jquery.once.js?v=1.2'\n",
      "http://pythonscraping.com/misc/drupal.js?q4na2g\n",
      "[Errno 22] Invalid argument: 'downloadedmisc/drupal.js?q4na2g'\n",
      "http://pythonscraping.com/sites/all/themes/skeletontheme/js/jquery.mobilemenu.js?q4na2g\n",
      "[Errno 22] Invalid argument: 'downloadedsites/all/themes/skeletontheme/js/jquery.mobilemenu.js?q4na2g'\n",
      "http://pythonscraping.com/sites/all/modules/google_analytics/googleanalytics.js?q4na2g\n",
      "[Errno 22] Invalid argument: 'downloadedsites/all/modules/google_analytics/googleanalytics.js?q4na2g'\n",
      "http://pythonscraping.com/sites/default/files/lrg_0.jpg\n",
      "이미지 다운로드 성공\n",
      "http://pythonscraping.com//https://covers.oreillystatic.com/images/0636920078067/lrg.jpg\n",
      "[WinError 123] 파일 이름, 디렉터리 이름 또는 볼륨 레이블 구문이 잘못되었습니다: 'downloaded/https:'\n",
      "http://pythonscraping.com/img/lrg%20(1).jpg\n",
      "이미지 다운로드 성공\n"
     ]
    }
   ],
   "source": [
    "# 오류\n",
    "# 모든 이미지 파일 다 받을 생각으로 넣었는데 오류 난다.\n",
    "for download in downloadList:\n",
    "    fileUrl = getAbsoluteUrl(baseUrl, download['src'])\n",
    "    if fileUrl is not None:\n",
    "        print(fileUrl)\n",
    "    try:\n",
    "        urlretrieve(fileUrl, getDownloadPath(baseUrl, fileUrl, download_dir))\n",
    "        print(\"이미지 다운로드 성공\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터를 csv로 저장\n",
    "\n",
    "* `.csv` 파일 : 쉼표로 구분된 파일. 각 행은 줄바꿈 문자로, 열은 쉼표로 구분한다.\n",
    "* `csv` 라이브러리\n",
    "\n",
    "---\n",
    "파이썬은 파일을 만들 때 에러를 일으키지 않는다. 즉, 이미 존재한다면 경고 없이 새 데이터로 덮어 써서 만든다. \n",
    "\n",
    "---\n",
    "HTML 테이블 가져와서 CSV 파일 만들기를 할 때, 사실, 한 번만 작업을 수행하면 될 때는 굳이 함수화하지 않고, 엑셀이나 스프레드시트에 붙여넣어서 작업할 수도 있다.\n",
    "\n",
    "\n",
    "* 기초 ver\n",
    "    - `html` 테이블을 가져와서 csv 파일로 만든다.\n",
    "    - 다른 태그들은 제거하지 않고 만든다.\n",
    "* 종합 ver\n",
    "    - `BeautifulSoup`와 `get_text()` 함수를 사용해 태그를 제거한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기초 ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module import\n",
    "import csv\n",
    "\n",
    "# csv 파일 읽기, 쓰기 모드. 없기 때문에 생성한다.\n",
    "csvFile = open('test.csv', 'w+')\n",
    "try:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerow((\"number\", \"number +2\", \"number x2\"))\n",
    "    for i in range(10):\n",
    "        writer.writerow( (i, i+2, i*2))\n",
    "finally: # 예외의 발생 여부와 관계없이 항상 실행되는 절\n",
    "    csvFile.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 종합 ver\n",
    "\n",
    "* 위키피디아의 텍스트 에디터 비교 페이지에서 HTML 테이블을 CSV 파일로 가져온다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'cp949' codec can't encode character '\\u2011' in position 78: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-0ac7860893fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'td'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'th'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;31m# 각 행에서 td, th 칸에 있는 텍스트들이 표의 글자 내용이다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mcsvRow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvRow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mcsvFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'cp949' codec can't encode character '\\u2011' in position 78: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "# module import\n",
    "import csv\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen(\"https://en.wikipedia.org/wiki/Comparison_of_text_editors\")\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 현재 페이지의 첫 번째 테이블 가져온다.\n",
    "table = bs.findAll('table', {'class' : 'wikitable'})[0] # 첫 번째\n",
    "rows = table.findAll('tr') # 각 행의 태그는 tr이다.\n",
    "\n",
    "# csv파일로 읽는다.\n",
    "csvFile = open(\"editors.csv\", \"wt+\") # 없으면 만든다.\n",
    "writer = csv.writer(csvFile)\n",
    "try:\n",
    "    for row in rows:\n",
    "        csvRow = []\n",
    "        for cell in row.findAll(['td', 'th']) : # 각 행에서 td, th 칸에 있는 텍스트들이 표의 글자 내용이다.\n",
    "            csvRow.append(cell.get_text())\n",
    "            writer.writerow(csvRow)\n",
    "finally:\n",
    "    csvFile.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
